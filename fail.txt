[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 18:33:35,736] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 18:33:36,296] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 18:33:36,358] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:33:36,365] INFO starting (kafka.server.KafkaServer)
[2024-08-26 18:33:36,367] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 18:33:36,397] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:33:36,404] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,404] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,404] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,404] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,404] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,404] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,405] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,408] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:33:36,416] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 18:33:36,427] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:33:36,433] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:33:36,437] INFO Opening socket connection to server zookeeper/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:33:36,448] INFO Socket connection established, initiating session, client: /172.19.0.2:49510, server: zookeeper/172.19.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:33:36,491] INFO Session establishment complete on server zookeeper/172.19.0.4:2181, sessionid = 0x1918ff701710000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:33:36,496] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:33:36,911] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 18:33:36,916] WARN No meta.properties file under dir /kafka/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2024-08-26 18:33:37,006] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:33:37,026] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:33:37,062] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:33:37,062] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:33:37,063] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:33:37,103] INFO Log directory /kafka/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2024-08-26 18:33:37,117] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 18:33:37,132] INFO Logs loading complete in 15 ms. (kafka.log.LogManager)
[2024-08-26 18:33:37,154] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 18:33:37,159] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 18:33:37,714] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 18:33:37,801] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 18:33:37,802] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 18:33:37,838] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:37,839] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:37,841] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:37,844] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:37,871] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:33:37,907] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 18:33:37,939] INFO Stat of the created znode at /brokers/ids/1 is: 39,39,1724697217926,1724697217926,1,0,0,113029756704849920,184,0,39
 (kafka.zk.KafkaZkClient)
[2024-08-26 18:33:37,940] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka-1,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 39 (kafka.zk.KafkaZkClient)
[2024-08-26 18:33:38,062] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:38,067] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:38,068] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:38,088] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2024-08-26 18:33:38,122] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:33:38,127] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:33:38,145] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 18 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:38,159] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2024-08-26 18:33:38,205] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 18:33:38,209] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-08-26 18:33:38,210] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 18:33:38,287] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:33:38,350] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-08-26 18:33:38,407] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2024-08-26 18:33:38,430] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:33:38,430] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:33:38,430] INFO Kafka startTimeMs: 1724697218407 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:33:38,435] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-08-26 18:33:39,064] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-31, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:33:39,194] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,205] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2024-08-26 18:33:39,209] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-1/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,210] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2024-08-26 18:33:39,211] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,213] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,243] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,243] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,244] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-1/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,244] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2024-08-26 18:33:39,244] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,244] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,253] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,253] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,254] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-1/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,254] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2024-08-26 18:33:39,254] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,255] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,265] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,266] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,267] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-1/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,267] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2024-08-26 18:33:39,267] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,267] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,280] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,281] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,282] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-1/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,283] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2024-08-26 18:33:39,283] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,283] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,291] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,291] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,292] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-1/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,293] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2024-08-26 18:33:39,293] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,293] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,305] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,306] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,306] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-1/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,306] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2024-08-26 18:33:39,307] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,307] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,317] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,318] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,320] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-1/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,320] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2024-08-26 18:33:39,320] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,320] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,331] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,332] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,333] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-1/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,333] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2024-08-26 18:33:39,333] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,333] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,342] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,343] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,343] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-1/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,343] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2024-08-26 18:33:39,343] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,343] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,357] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,357] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,359] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-1/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,359] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2024-08-26 18:33:39,359] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,359] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,373] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,373] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,374] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-1/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,374] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2024-08-26 18:33:39,374] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,374] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,391] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,392] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,393] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-1/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,393] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2024-08-26 18:33:39,393] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,393] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,403] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,404] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,405] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-1/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,406] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2024-08-26 18:33:39,406] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,406] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,416] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,417] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,417] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-1/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,417] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2024-08-26 18:33:39,417] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,418] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,425] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,426] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,427] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-1/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,427] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2024-08-26 18:33:39,427] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,427] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,444] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,445] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:33:39,446] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-1/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,446] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2024-08-26 18:33:39,446] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,446] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,454] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,456] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,458] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-1/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,459] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2024-08-26 18:33:39,459] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,459] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,473] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,474] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,475] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-1/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,475] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2024-08-26 18:33:39,475] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,475] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,490] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,490] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,491] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-1/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,492] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2024-08-26 18:33:39,493] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,493] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,505] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,506] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,507] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-1/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,508] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2024-08-26 18:33:39,508] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,508] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,521] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,523] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,524] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-1/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,524] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2024-08-26 18:33:39,524] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,524] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,539] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,540] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,544] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-1/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,545] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2024-08-26 18:33:39,545] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,546] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,557] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,559] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,563] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-1/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,563] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2024-08-26 18:33:39,563] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,564] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,582] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,584] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:33:39,585] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-1/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,585] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2024-08-26 18:33:39,585] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,585] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:33:39,623] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,624] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,625] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-1/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,626] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,626] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,638] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,639] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:33:39,640] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-1/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,640] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2024-08-26 18:33:39,640] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,645] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,646] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,647] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-1/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,649] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2024-08-26 18:33:39,650] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,657] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,658] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,660] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-1/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,661] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2024-08-26 18:33:39,661] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,668] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,669] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,671] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-1/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,671] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2024-08-26 18:33:39,671] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,675] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,676] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,678] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-1/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,678] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2024-08-26 18:33:39,678] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,685] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,685] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,686] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-1/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,686] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2024-08-26 18:33:39,687] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,691] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,692] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,693] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-1/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,693] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2024-08-26 18:33:39,693] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,700] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,700] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,702] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-1/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,703] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2024-08-26 18:33:39,703] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,713] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,719] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:33:39,720] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-1/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,720] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2024-08-26 18:33:39,720] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,731] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,731] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,732] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-1/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,732] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2024-08-26 18:33:39,732] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,736] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,737] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,737] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-1/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,738] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2024-08-26 18:33:39,738] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,743] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,744] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,744] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-1/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,745] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2024-08-26 18:33:39,745] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,751] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,751] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,752] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-1/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,752] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2024-08-26 18:33:39,752] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,758] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,762] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:33:39,764] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-1/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,764] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2024-08-26 18:33:39,764] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,773] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,773] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:33:39,774] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-1/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,774] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2024-08-26 18:33:39,781] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,791] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,793] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:33:39,794] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-1/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,795] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2024-08-26 18:33:39,795] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,801] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,801] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,804] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-1/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,804] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2024-08-26 18:33:39,804] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,809] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,810] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,810] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-1/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,811] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2024-08-26 18:33:39,811] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,817] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,817] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:33:39,818] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-1/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,818] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2024-08-26 18:33:39,818] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,825] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,825] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:33:39,827] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-1/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,827] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2024-08-26 18:33:39,827] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,835] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,836] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:33:39,836] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-1/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,836] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2024-08-26 18:33:39,836] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,844] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,846] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:33:39,849] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-1/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,850] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2024-08-26 18:33:39,850] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,859] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,860] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:33:39,862] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-1/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,862] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2024-08-26 18:33:39,862] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,872] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:33:39,873] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:33:39,874] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-1/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:33:39,874] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2024-08-26 18:33:39,874] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:33:39,875] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-28, __consumer_offsets-6, __consumer_offsets-32, __consumer_offsets-10, __consumer_offsets-14, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-48, __consumer_offsets-22, __consumer_offsets-0, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-4, __consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-16, __consumer_offsets-12, __consumer_offsets-20, __consumer_offsets-42, __consumer_offsets-2, __consumer_offsets-46, __consumer_offsets-24) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:33:39,969] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:39,973] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(__consumer_offsets-22 -> (offset=0, leaderEpoch=0), __consumer_offsets-30 -> (offset=0, leaderEpoch=0), __consumer_offsets-8 -> (offset=0, leaderEpoch=0), __consumer_offsets-4 -> (offset=0, leaderEpoch=0), __consumer_offsets-46 -> (offset=0, leaderEpoch=0), __consumer_offsets-16 -> (offset=0, leaderEpoch=0), __consumer_offsets-28 -> (offset=0, leaderEpoch=0), __consumer_offsets-36 -> (offset=0, leaderEpoch=0), __consumer_offsets-42 -> (offset=0, leaderEpoch=0), __consumer_offsets-18 -> (offset=0, leaderEpoch=0), __consumer_offsets-24 -> (offset=0, leaderEpoch=0), __consumer_offsets-38 -> (offset=0, leaderEpoch=0), __consumer_offsets-48 -> (offset=0, leaderEpoch=0), __consumer_offsets-2 -> (offset=0, leaderEpoch=0), __consumer_offsets-6 -> (offset=0, leaderEpoch=0), __consumer_offsets-14 -> (offset=0, leaderEpoch=0), __consumer_offsets-20 -> (offset=0, leaderEpoch=0), __consumer_offsets-0 -> (offset=0, leaderEpoch=0), __consumer_offsets-44 -> (offset=0, leaderEpoch=0), __consumer_offsets-12 -> (offset=0, leaderEpoch=0), __consumer_offsets-26 -> (offset=0, leaderEpoch=0), __consumer_offsets-34 -> (offset=0, leaderEpoch=0), __consumer_offsets-10 -> (offset=0, leaderEpoch=0), __consumer_offsets-32 -> (offset=0, leaderEpoch=0), __consumer_offsets-40 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:33:39,995] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-28 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,004] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,006] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,006] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,007] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,008] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,008] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-32 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,008] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,010] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-36 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,010] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,011] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-14 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,014] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,015] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-44 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,016] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,018] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-18 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,019] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,019] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-48 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,019] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,020] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-40 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,020] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,020] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,020] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-30 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-26 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-34 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,021] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,021] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,022] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,022] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,022] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-38 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,022] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,022] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-12 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,022] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,022] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-42 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,022] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,022] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-20 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,022] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,024] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-46 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,025] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,026] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-24 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,027] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,027] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:33:40,029] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:33:40,055] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,065] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,067] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,069] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,071] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,075] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,076] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,076] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,077] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,077] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,078] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,078] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,078] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,082] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,091] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 24 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,091] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,092] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,093] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,095] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,097] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,098] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,101] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,101] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,103] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,107] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,115] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,117] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,117] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,118] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,119] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,121] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,127] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,134] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,137] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,140] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,145] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,145] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,146] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,146] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,152] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,157] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-2. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-8. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-20. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,159] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-26. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,160] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-32. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,160] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,161] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,162] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,162] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-44. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,162] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,163] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,164] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,164] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,165] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,165] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,166] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,167] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,167] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,167] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:33:40,198] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-38 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,201] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-16 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,201] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-8 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,201] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,201] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-24 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,202] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-46 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,202] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-32 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-10 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-48 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-18 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-40 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-34 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,204] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-4 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-26 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-42 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-20 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-12 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-28 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-6 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-44 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-36 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-14 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-30 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,205] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-22 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:33:40,206] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:37:27,092] INFO Creating topic twitter-stream with configuration {} and initial partition assignment Map(2 -> ArrayBuffer(1, 2), 1 -> ArrayBuffer(2, 1), 0 -> ArrayBuffer(1, 2)) (kafka.zk.AdminZkClient)
[2024-08-26 18:37:27,135] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(twitter-stream-2, twitter-stream-0) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:37:27,138] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:37:27,139] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:37:27,140] INFO Created log for partition twitter-stream-2 in /kafka/kafka-logs-1/twitter-stream-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:37:27,143] INFO [Partition twitter-stream-2 broker=1] No checkpointed highwatermark is found for partition twitter-stream-2 (kafka.cluster.Partition)
[2024-08-26 18:37:27,143] INFO [Partition twitter-stream-2 broker=1] Log loaded for partition twitter-stream-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:37:27,143] INFO [Partition twitter-stream-2 broker=1] twitter-stream-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:37:27,151] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:37:27,151] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2024-08-26 18:37:27,152] INFO Created log for partition twitter-stream-0 in /kafka/kafka-logs-1/twitter-stream-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:37:27,152] INFO [Partition twitter-stream-0 broker=1] No checkpointed highwatermark is found for partition twitter-stream-0 (kafka.cluster.Partition)
[2024-08-26 18:37:27,152] INFO [Partition twitter-stream-0 broker=1] Log loaded for partition twitter-stream-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:37:27,152] INFO [Partition twitter-stream-0 broker=1] twitter-stream-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:37:27,163] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:37:27,163] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:37:27,164] INFO Created log for partition twitter-stream-1 in /kafka/kafka-logs-1/twitter-stream-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2024-08-26 18:37:27,164] INFO [Partition twitter-stream-1 broker=1] No checkpointed highwatermark is found for partition twitter-stream-1 (kafka.cluster.Partition)
[2024-08-26 18:37:27,164] INFO [Partition twitter-stream-1 broker=1] Log loaded for partition twitter-stream-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:37:27,164] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(twitter-stream-1) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:37:27,165] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(twitter-stream-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:37:27,517] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition twitter-stream-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:37:27,518] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:38:10,552] INFO [GroupCoordinator 1]: Preparing to rebalance group twitter-group in state PreparingRebalance with old generation 0 (__consumer_offsets-25) (reason: Adding new member rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:38:10,564] INFO [GroupCoordinator 1]: Stabilized group twitter-group generation 1 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:38:10,578] INFO [GroupCoordinator 1]: Assignment received from leader for group twitter-group for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:40:47,845] INFO Unable to read additional data from server sessionid 0x1918ff701710000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:40:47,998] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:40:48,002] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 18:40:48,003] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-08-26 18:40:53,953] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper: Try again
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:40:54,035] WARN Session 0x1918ff701710000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 18:40:54,137] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:40:55,137] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:40:55,628] WARN Session 0x1918ff701710000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 18:40:56,728] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:40:57,621] WARN Session 0x1918ff701710000 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 18:44:10,748] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 18:44:11,321] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 18:44:11,378] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:44:11,384] INFO starting (kafka.server.KafkaServer)
[2024-08-26 18:44:11,385] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 18:44:11,408] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:44:11,415] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,415] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,416] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,419] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:11,425] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 18:44:11,433] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:44:11,436] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:44:11,442] INFO Opening socket connection to server zookeeper/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:44:11,453] INFO Socket connection established, initiating session, client: /172.19.0.3:36250, server: zookeeper/172.19.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:44:11,472] INFO Session establishment complete on server zookeeper/172.19.0.4:2181, sessionid = 0x1919000b1600001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:44:11,476] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:44:11,787] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 18:44:11,893] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:44:11,905] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:44:11,951] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:11,951] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:11,955] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:12,019] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 18:44:12,104] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,109] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,164] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,166] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 100 ms (kafka.log.Log)
[2024-08-26 18:44:12,191] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,192] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,209] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,209] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2024-08-26 18:44:12,216] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,216] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,218] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,219] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:44:12,227] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,228] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,234] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,235] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:44:12,241] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,241] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,247] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,247] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,252] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,253] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,254] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,255] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:44:12,261] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,261] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,270] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,272] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2024-08-26 18:44:12,279] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,280] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,286] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,286] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,294] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,295] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,301] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,302] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,312] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,313] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,315] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,316] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:44:12,329] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,330] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,332] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,332] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:44:12,341] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,341] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,347] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,348] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 18:44:12,354] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,354] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,356] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,357] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:44:12,364] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,364] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,367] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,368] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:44:12,372] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,372] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,375] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,375] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:44:12,380] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,381] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,387] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,388] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,392] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,393] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,398] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,401] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:44:12,406] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,407] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,414] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,414] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:44:12,420] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,422] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,423] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,424] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:44:12,430] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,430] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,435] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,435] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:44:12,440] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,441] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,442] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,443] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:44:12,447] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,447] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,453] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,454] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,458] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,459] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,463] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,464] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:44:12,473] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,475] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,480] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,481] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 18:44:12,494] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,495] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,497] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,499] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,505] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,506] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,509] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,512] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,523] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,524] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,531] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,531] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2024-08-26 18:44:12,538] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,540] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,542] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,542] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:44:12,546] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,546] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,555] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,555] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:44:12,562] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,563] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,568] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,569] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,572] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,573] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,581] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,583] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 18:44:12,587] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,588] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,594] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,594] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,598] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,598] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,599] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,600] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,603] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,604] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,609] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,609] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,613] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,613] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,620] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,621] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:44:12,625] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,625] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,632] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,633] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,636] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,636] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,644] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2024-08-26 18:44:12,658] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,661] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/kafka/kafka-logs-1/__consumer_offsets-25/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2024-08-26 18:44:12,672] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 38 ms (kafka.log.Log)
[2024-08-26 18:44:12,675] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,675] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,680] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,680] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:44:12,683] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,684] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,688] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,689] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:44:12,692] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,692] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,693] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,694] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:44:12,696] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,696] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,698] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,698] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,701] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,701] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,702] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,702] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,705] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,705] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,712] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,713] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:44:12,715] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,715] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,717] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,717] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,720] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,720] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,721] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,722] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,724] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,724] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,726] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,726] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,728] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,729] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,730] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,731] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:44:12,733] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,734] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,740] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,740] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:44:12,745] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,745] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,754] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,754] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:44:12,758] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,758] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,765] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,766] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:44:12,768] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,769] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,770] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,770] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,772] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,773] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,774] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,774] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,776] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:44:12,776] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,777] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:44:12,778] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:44:12,781] INFO Logs loading complete in 762 ms. (kafka.log.LogManager)
[2024-08-26 18:44:12,798] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 18:44:12,800] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 18:44:13,221] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 18:44:13,263] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 18:44:13,264] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 18:44:13,289] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,290] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,293] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,300] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,315] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:44:13,394] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 18:44:13,426] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '113029756704849920' does not match current session '113029798311231489' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-08-26 18:44:13,434] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2024-08-26 18:44:13,436] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 18:44:13,438] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2024-08-26 18:44:13,443] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2024-08-26 18:44:13,449] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2024-08-26 18:44:13,450] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:44:13,450] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:44:13,451] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:44:13,453] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:44:13,459] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:44:13,459] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 18:44:13,461] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 18:44:13,461] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,491] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,491] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,492] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,690] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,690] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,691] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,693] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,693] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,694] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,700] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,700] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:44:13,707] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2024-08-26 18:44:13,708] INFO Shutting down. (kafka.log.LogManager)
[2024-08-26 18:44:13,801] INFO Shutdown complete. (kafka.log.LogManager)
[2024-08-26 18:44:13,802] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:44:13,907] INFO Session: 0x1919000b1600001 closed (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:44:13,908] INFO EventThread shut down for session: 0x1919000b1600001 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:44:13,909] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:44:13,910] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:13,952] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:13,952] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:13,952] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,952] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,952] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,952] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,956] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,956] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:44:14,957] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2024-08-26 18:44:14,995] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2024-08-26 18:44:15,003] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2024-08-26 18:44:15,003] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2024-08-26 18:44:15,004] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 18:56:26,528] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 18:56:27,073] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 18:56:27,137] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:56:27,145] INFO starting (kafka.server.KafkaServer)
[2024-08-26 18:56:27,147] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 18:56:27,169] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:56:27,175] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,175] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,175] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,175] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,175] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,176] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,179] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:56:27,185] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 18:56:27,192] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:56:27,195] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:56:27,203] INFO Opening socket connection to server zookeeper/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:56:27,209] INFO Socket connection established, initiating session, client: /172.19.0.2:55678, server: zookeeper/172.19.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:56:27,220] INFO Session establishment complete on server zookeeper/172.19.0.4:2181, sessionid = 0x1919000b1600002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:56:27,224] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:56:27,523] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 18:56:27,620] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:56:27,637] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:56:27,671] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:56:27,673] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:56:27,674] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:56:27,720] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 18:56:27,806] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,819] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2024-08-26 18:56:27,832] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,833] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,838] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,839] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,844] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,845] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,850] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,850] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,855] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,855] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,861] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,862] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:56:27,870] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,870] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:56:27,878] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,878] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:56:27,884] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,884] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,889] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,889] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,894] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,894] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,899] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,899] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,904] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,904] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,908] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,909] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,914] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,914] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,919] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,919] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,924] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,924] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,929] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,929] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,935] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,935] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,943] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,943] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,947] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,948] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,952] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,952] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,956] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,957] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,961] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,962] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,969] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,969] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:56:27,974] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,974] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,978] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,979] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:27,984] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,984] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,987] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,988] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,991] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,992] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:27,996] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:27,997] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:28,005] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,005] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,008] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,009] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,012] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,013] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,020] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,020] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:56:28,049] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,056] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/kafka/kafka-logs-1/__consumer_offsets-25/00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2024-08-26 18:56:28,073] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 51 ms (kafka.log.Log)
[2024-08-26 18:56:28,076] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,077] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,080] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,081] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,084] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,085] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,088] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,089] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,093] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,094] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:28,102] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,104] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:56:28,108] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,109] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:28,112] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,113] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,116] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,116] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,120] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,120] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,124] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,124] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,128] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,128] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,131] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,132] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:28,135] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,136] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:56:28,139] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,139] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,143] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:56:28,143] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 18:56:28,146] INFO Logs loading complete in 426 ms. (kafka.log.LogManager)
[2024-08-26 18:56:28,161] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 18:56:28,162] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 18:56:28,584] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 18:56:28,636] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 18:56:28,637] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 18:56:28,674] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,674] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,676] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,677] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,696] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:56:28,772] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 18:56:28,799] INFO Stat of the created znode at /brokers/ids/1 is: 222,222,1724698588786,1724698588786,1,0,0,113029798311231490,184,0,222
 (kafka.zk.KafkaZkClient)
[2024-08-26 18:56:28,799] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka-1,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 222 (kafka.zk.KafkaZkClient)
[2024-08-26 18:56:28,895] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,901] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,902] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:28,995] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:56:29,004] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:56:29,019] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 22 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:29,039] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2024-08-26 18:56:29,140] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 18:56:29,150] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-08-26 18:56:29,152] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 18:56:29,269] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:56:29,414] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-08-26 18:56:29,488] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2024-08-26 18:56:29,494] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:56:29,494] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:56:29,495] INFO Kafka startTimeMs: 1724698589489 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 18:56:29,496] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-08-26 18:56:29,689] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(twitter-stream-2, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, twitter-stream-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-31, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:56:29,704] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,706] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,737] INFO [Partition twitter-stream-2 broker=1] Log loaded for partition twitter-stream-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,737] INFO [Partition twitter-stream-2 broker=1] twitter-stream-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,748] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,748] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,757] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,757] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,770] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,770] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,783] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,784] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,793] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,795] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,804] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,804] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,814] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,814] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,823] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,823] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,830] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,830] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,836] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,836] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,843] INFO [Partition twitter-stream-0 broker=1] Log loaded for partition twitter-stream-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,843] INFO [Partition twitter-stream-0 broker=1] twitter-stream-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,850] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,850] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,856] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,856] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,863] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,863] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,869] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,870] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,876] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,876] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,882] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,882] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,890] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,890] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,896] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,897] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,904] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,904] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,911] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,911] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,918] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 1 (kafka.cluster.Partition)
[2024-08-26 18:56:29,918] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at leader epoch 0 from offset 1 with high watermark 1. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,921] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,921] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,927] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,927] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,933] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,933] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 18:56:29,965] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,968] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,973] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,976] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,979] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,983] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,986] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,988] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,991] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,993] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,995] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:29,998] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,001] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,004] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,006] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,009] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,011] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,014] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,017] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,020] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,025] INFO [Partition twitter-stream-1 broker=1] Log loaded for partition twitter-stream-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,028] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,031] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,033] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,037] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,040] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 18:56:30,040] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-28, __consumer_offsets-6, __consumer_offsets-32, __consumer_offsets-10, __consumer_offsets-14, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-48, __consumer_offsets-22, __consumer_offsets-0, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-4, __consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-16, twitter-stream-1, __consumer_offsets-12, __consumer_offsets-20, __consumer_offsets-42, __consumer_offsets-2, __consumer_offsets-46, __consumer_offsets-24) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:56:30,074] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,088] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(__consumer_offsets-22 -> (offset=0, leaderEpoch=0), __consumer_offsets-30 -> (offset=0, leaderEpoch=0), __consumer_offsets-8 -> (offset=0, leaderEpoch=0), __consumer_offsets-4 -> (offset=0, leaderEpoch=0), __consumer_offsets-46 -> (offset=0, leaderEpoch=0), __consumer_offsets-16 -> (offset=0, leaderEpoch=0), __consumer_offsets-28 -> (offset=0, leaderEpoch=0), __consumer_offsets-36 -> (offset=0, leaderEpoch=0), __consumer_offsets-42 -> (offset=0, leaderEpoch=0), __consumer_offsets-18 -> (offset=0, leaderEpoch=0), __consumer_offsets-24 -> (offset=0, leaderEpoch=0), __consumer_offsets-38 -> (offset=0, leaderEpoch=0), __consumer_offsets-48 -> (offset=0, leaderEpoch=0), __consumer_offsets-2 -> (offset=0, leaderEpoch=0), __consumer_offsets-6 -> (offset=0, leaderEpoch=0), __consumer_offsets-14 -> (offset=0, leaderEpoch=0), __consumer_offsets-20 -> (offset=0, leaderEpoch=0), __consumer_offsets-0 -> (offset=0, leaderEpoch=0), __consumer_offsets-44 -> (offset=0, leaderEpoch=0), __consumer_offsets-12 -> (offset=0, leaderEpoch=0), __consumer_offsets-26 -> (offset=0, leaderEpoch=0), twitter-stream-1 -> (offset=0, leaderEpoch=0), __consumer_offsets-34 -> (offset=0, leaderEpoch=0), __consumer_offsets-10 -> (offset=0, leaderEpoch=0), __consumer_offsets-32 -> (offset=0, leaderEpoch=0), __consumer_offsets-40 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:56:30,090] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-28 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,096] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,097] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,097] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,097] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-32 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-36 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-14 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-44 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-18 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,098] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-48 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,098] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-40 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-30 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,099] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-26 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,099] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-34 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-38 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition twitter-stream-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-12 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,100] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,100] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-42 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,101] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,101] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-20 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,101] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,101] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-46 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,101] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,101] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-24 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,101] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,101] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 18:56:30,101] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 18:56:30,108] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,115] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,115] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,116] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,117] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,118] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,118] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,118] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,121] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,123] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,124] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,125] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,126] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,126] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,126] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,181] INFO Static member MemberMetadata(memberId=rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db, groupInstanceId=Some(null), clientId=rdkafka, clientHost=/172.19.0.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group twitter-group loaded with member id rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-08-26 18:56:30,203] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-38 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,209] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-16 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,209] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-8 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,209] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,206] INFO [GroupCoordinator 1]: Loading group metadata for twitter-group with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:56:30,212] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-24 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,212] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-46 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,213] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-32 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,213] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-10 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,213] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-48 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,213] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-40 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,214] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-18 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,215] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-34 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,215] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-4 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,216] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-26 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,216] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-42 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,216] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-20 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-12 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-28 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-6 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-44 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-36 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,226] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-14 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,227] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-30 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,227] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-22 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,227] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition __consumer_offsets-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,227] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition twitter-stream-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2024-08-26 18:56:30,230] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 121 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,244] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,245] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,251] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,253] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,256] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,257] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,257] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,258] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,258] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,259] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,259] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,260] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,261] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,262] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,264] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,264] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,265] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,265] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,266] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,267] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,268] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,269] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,273] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,273] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,273] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,274] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,274] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-2. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,274] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,274] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-8. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-20. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-26. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-32. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,275] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-44. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,277] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 18:56:30,939] INFO [GroupCoordinator 1]: Preparing to rebalance group twitter-group in state PreparingRebalance with old generation 1 (__consumer_offsets-25) (reason: Adding new member rdkafka-5a1f7171-d18e-4310-9504-fdc7373bfec2 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:57:15,231] INFO [GroupCoordinator 1]: Member rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db in group twitter-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:57:15,239] INFO [GroupCoordinator 1]: Stabilized group twitter-group generation 2 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:57:15,250] INFO [GroupCoordinator 1]: Assignment received from leader for group twitter-group for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 18:58:20,535] INFO Unable to read additional data from server sessionid 0x1919000b1600002, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:58:20,867] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:58:20,869] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 18:58:20,870] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-08-26 18:58:26,643] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper: Try again
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:58:27,159] WARN Session 0x1919000b1600002 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 18:58:27,262] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:58:28,261] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:58:28,654] WARN Session 0x1919000b1600002 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 18:58:29,755] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 18:58:30,280] WARN Session 0x1919000b1600002 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 18:59:46,874] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 18:59:47,417] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 18:59:47,503] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 18:59:47,510] INFO starting (kafka.server.KafkaServer)
[2024-08-26 18:59:47,512] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 18:59:47,541] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:59:47,552] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,553] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,553] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,553] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,553] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,553] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,554] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,555] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,555] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,555] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,555] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,555] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,559] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:47,567] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 18:59:47,576] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:59:47,580] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:59:47,589] INFO Opening socket connection to server zookeeper/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:59:47,597] INFO Socket connection established, initiating session, client: /172.19.0.3:60342, server: zookeeper/172.19.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:59:47,608] INFO Session establishment complete on server zookeeper/172.19.0.4:2181, sessionid = 0x191900efa410001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:59:47,612] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:59:47,934] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 18:59:48,059] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:59:48,085] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 18:59:48,124] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:48,125] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:48,126] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:48,175] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 18:59:48,255] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,258] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,297] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,298] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2024-08-26 18:59:48,312] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,312] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,334] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,335] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2024-08-26 18:59:48,341] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,341] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,344] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,347] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:59:48,351] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,352] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,356] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,357] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:59:48,365] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,365] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,372] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,373] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:59:48,380] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,380] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,382] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,383] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,389] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,390] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,395] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,396] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:59:48,403] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,404] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,409] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,409] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:59:48,415] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,416] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,423] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,425] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 18:59:48,431] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,431] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,433] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,434] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,438] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,438] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,440] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,441] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,452] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,452] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,463] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,464] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2024-08-26 18:59:48,469] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,469] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,471] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,472] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,478] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,478] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,480] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,481] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,487] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,487] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,489] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,489] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:59:48,494] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,494] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,501] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,503] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:59:48,508] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,509] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,516] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,517] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:59:48,521] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,521] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,530] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,531] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 18:59:48,536] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,536] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,538] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,538] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:59:48,543] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,543] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,549] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,550] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:48,555] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,555] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,558] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,558] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,562] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,562] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,569] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,570] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:48,574] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,579] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,581] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,583] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:59:48,587] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,587] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,589] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,589] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:48,596] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,596] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,600] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,603] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:48,610] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,611] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,612] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,613] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:59:48,616] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,617] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,625] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,625] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:59:48,632] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,632] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,633] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,637] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 18:59:48,641] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,641] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,647] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,647] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 18:59:48,655] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,657] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,663] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,666] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 18:59:48,672] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,673] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,681] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,685] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2024-08-26 18:59:48,695] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,700] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,714] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,715] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2024-08-26 18:59:48,722] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,722] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,724] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,724] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:48,729] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,730] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,739] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,739] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:59:48,749] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,751] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,760] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,762] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2024-08-26 18:59:48,765] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,765] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,771] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,772] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:48,786] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,786] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,803] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2024-08-26 18:59:48,819] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,821] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/kafka/kafka-logs-1/__consumer_offsets-25/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2024-08-26 18:59:48,834] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 56 ms (kafka.log.Log)
[2024-08-26 18:59:48,844] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,848] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,858] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,862] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2024-08-26 18:59:48,880] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,880] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,886] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,886] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:59:48,897] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,898] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,900] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,902] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:59:48,910] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,910] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,912] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,913] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 18:59:48,920] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,920] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,923] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,924] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,933] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,934] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,941] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,943] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 18:59:48,948] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,949] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,950] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,951] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 18:59:48,954] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,954] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,955] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,955] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:48,958] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,958] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,960] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,960] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:48,963] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,963] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,964] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,965] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:48,969] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,969] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,974] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,975] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 18:59:48,981] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,981] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,986] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:48,987] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:48,993] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:48,994] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,000] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,001] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 18:59:49,009] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:49,011] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,015] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,017] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 18:59:49,026] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:49,027] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,030] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,031] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 18:59:49,036] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 18:59:49,036] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,038] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 18:59:49,038] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 18:59:49,043] INFO Logs loading complete in 868 ms. (kafka.log.LogManager)
[2024-08-26 18:59:49,072] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 18:59:49,074] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 18:59:49,628] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 18:59:49,680] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 18:59:49,681] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 18:59:49,715] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:49,716] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:49,717] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:49,720] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:49,738] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:59:49,842] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 18:59:49,894] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '113029798311231490' does not match current session '113029859663478785' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-08-26 18:59:49,914] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2024-08-26 18:59:49,921] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 18:59:49,923] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2024-08-26 18:59:49,935] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2024-08-26 18:59:49,950] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2024-08-26 18:59:49,952] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:59:49,953] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:59:49,954] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 18:59:49,955] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:59:49,959] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-08-26 18:59:49,960] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 18:59:49,964] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 18:59:49,965] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,119] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,119] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,120] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,316] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,317] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,317] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,320] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,320] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,320] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,321] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,322] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 18:59:50,332] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2024-08-26 18:59:50,333] INFO Shutting down. (kafka.log.LogManager)
[2024-08-26 18:59:50,456] INFO Shutdown complete. (kafka.log.LogManager)
[2024-08-26 18:59:50,459] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:59:50,566] INFO Session: 0x191900efa410001 closed (org.apache.zookeeper.ZooKeeper)
[2024-08-26 18:59:50,568] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 18:59:50,569] INFO EventThread shut down for session: 0x191900efa410001 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 18:59:50,570] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,125] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,125] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,125] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,126] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,126] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,126] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,127] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,127] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 18:59:51,128] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2024-08-26 18:59:51,180] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2024-08-26 18:59:51,189] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2024-08-26 18:59:51,190] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2024-08-26 18:59:51,191] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 19:00:30,238] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 19:00:30,760] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 19:00:30,822] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 19:00:30,828] INFO starting (kafka.server.KafkaServer)
[2024-08-26 19:00:30,830] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 19:00:30,851] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:00:30,857] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,858] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,859] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,862] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:00:30,868] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 19:00:30,879] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:00:30,883] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:00:30,892] INFO Opening socket connection to server zookeeper/172.19.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:00:30,898] INFO Socket connection established, initiating session, client: /172.19.0.3:49526, server: zookeeper/172.19.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:00:30,914] INFO Session establishment complete on server zookeeper/172.19.0.4:2181, sessionid = 0x191900fa3e90001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:00:30,918] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:00:31,261] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 19:00:31,369] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 19:00:31,385] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 19:00:31,423] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:00:31,424] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:00:31,425] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:00:31,476] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 19:00:31,569] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,583] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2024-08-26 19:00:31,597] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,598] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,603] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,604] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,610] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,610] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,615] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,616] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,623] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,624] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:00:31,630] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,631] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,642] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,642] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,648] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,648] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,655] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,655] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,660] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,660] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,665] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,665] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,671] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,672] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,678] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,679] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,686] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,686] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,693] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,693] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,698] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,698] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,704] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,705] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,709] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,710] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,714] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,714] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,719] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,719] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,724] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,725] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,729] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,730] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,734] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,734] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,738] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,738] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,744] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,744] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,749] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,749] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,756] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,759] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 19:00:31,764] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,765] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,769] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,769] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,773] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,773] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,777] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,777] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,781] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,781] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,785] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,785] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,790] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,791] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,796] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,796] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,819] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,826] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/kafka/kafka-logs-1/__consumer_offsets-25/00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2024-08-26 19:00:31,841] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 43 ms (kafka.log.Log)
[2024-08-26 19:00:31,847] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,848] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:00:31,853] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,853] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,858] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,858] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,863] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,864] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,870] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,871] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,879] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,882] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:00:31,894] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,894] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 19:00:31,899] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,900] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,905] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,906] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:00:31,912] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,913] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:00:31,917] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,917] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,921] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,921] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,925] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,926] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:00:31,931] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,933] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:00:31,939] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,939] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,943] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:00:31,943] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2024-08-26 19:00:31,946] INFO Logs loading complete in 470 ms. (kafka.log.LogManager)
[2024-08-26 19:00:31,960] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 19:00:31,962] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 19:00:32,382] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 19:00:32,421] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 19:00:32,422] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 19:00:32,449] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,451] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,452] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,453] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,471] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 19:00:32,533] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 19:00:32,564] INFO Stat of the created znode at /brokers/ids/1 is: 290,290,1724698832551,1724698832551,1,0,0,113029862509838337,184,0,290
 (kafka.zk.KafkaZkClient)
[2024-08-26 19:00:32,565] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(kafka-1,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 290 (kafka.zk.KafkaZkClient)
[2024-08-26 19:00:32,666] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,677] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,681] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,740] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:00:32,744] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:00:32,758] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:32,773] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2024-08-26 19:00:32,822] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 19:00:32,835] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-08-26 19:00:32,835] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-08-26 19:00:32,903] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:00:32,953] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-08-26 19:00:33,014] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2024-08-26 19:00:33,026] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 19:00:33,026] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 19:00:33,026] INFO Kafka startTimeMs: 1724698833015 (org.apache.kafka.common.utils.AppInfoParser)
[2024-08-26 19:00:33,027] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2024-08-26 19:00:33,249] ERROR [KafkaApi-1] Number of alive brokers '0' does not meet the required replication factor '2' for the offsets topic (configured via 'offsets.topic.replication.factor'). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)
[2024-08-26 19:00:33,382] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(twitter-stream-2, __consumer_offsets-21, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, twitter-stream-0, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-31, __consumer_offsets-3, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-17, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-29) (kafka.server.ReplicaFetcherManager)
[2024-08-26 19:00:33,409] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,416] INFO [Partition __consumer_offsets-29 broker=1] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,442] INFO [Partition twitter-stream-2 broker=1] Log loaded for partition twitter-stream-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,442] INFO [Partition twitter-stream-2 broker=1] twitter-stream-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,452] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,452] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,461] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,464] INFO [Partition __consumer_offsets-7 broker=1] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,473] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,473] INFO [Partition __consumer_offsets-23 broker=1] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,480] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,480] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,490] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,490] INFO [Partition __consumer_offsets-1 broker=1] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,499] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,499] INFO [Partition __consumer_offsets-17 broker=1] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,507] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,507] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,515] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,515] INFO [Partition __consumer_offsets-49 broker=1] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,521] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,521] INFO [Partition __consumer_offsets-11 broker=1] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,529] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,529] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,536] INFO [Partition twitter-stream-0 broker=1] Log loaded for partition twitter-stream-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,537] INFO [Partition twitter-stream-0 broker=1] twitter-stream-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,542] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,542] INFO [Partition __consumer_offsets-43 broker=1] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,549] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,549] INFO [Partition __consumer_offsets-5 broker=1] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,557] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,557] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,565] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,565] INFO [Partition __consumer_offsets-37 broker=1] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,573] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,573] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,579] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,579] INFO [Partition __consumer_offsets-31 broker=1] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,587] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,587] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,593] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,593] INFO [Partition __consumer_offsets-47 broker=1] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,599] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,599] INFO [Partition __consumer_offsets-19 broker=1] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,605] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,606] INFO [Partition __consumer_offsets-35 broker=1] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,611] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 2 (kafka.cluster.Partition)
[2024-08-26 19:00:33,611] INFO [Partition __consumer_offsets-25 broker=1] __consumer_offsets-25 starts at leader epoch 0 from offset 2 with high watermark 2. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,613] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,614] INFO [Partition __consumer_offsets-41 broker=1] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,620] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,620] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,626] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,626] INFO [Partition __consumer_offsets-13 broker=1] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2024-08-26 19:00:33,658] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,661] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,664] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,667] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,671] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,674] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,676] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,679] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,684] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,686] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,692] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,695] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,698] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,700] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,703] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,705] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,707] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,710] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,713] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,715] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,718] INFO [Partition twitter-stream-1 broker=1] Log loaded for partition twitter-stream-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,720] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,723] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,726] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,728] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,732] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-08-26 19:00:33,733] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-28, __consumer_offsets-6, __consumer_offsets-32, __consumer_offsets-10, __consumer_offsets-14, __consumer_offsets-44, __consumer_offsets-36, __consumer_offsets-40, __consumer_offsets-18, __consumer_offsets-48, __consumer_offsets-22, __consumer_offsets-0, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-4, __consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-16, twitter-stream-1, __consumer_offsets-12, __consumer_offsets-20, __consumer_offsets-42, __consumer_offsets-2, __consumer_offsets-46, __consumer_offsets-24) (kafka.server.ReplicaFetcherManager)
[2024-08-26 19:00:33,760] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,781] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(__consumer_offsets-22 -> (offset=0, leaderEpoch=0), __consumer_offsets-30 -> (offset=0, leaderEpoch=0), __consumer_offsets-8 -> (offset=0, leaderEpoch=0), __consumer_offsets-4 -> (offset=0, leaderEpoch=0), __consumer_offsets-46 -> (offset=0, leaderEpoch=0), __consumer_offsets-16 -> (offset=0, leaderEpoch=0), __consumer_offsets-28 -> (offset=0, leaderEpoch=0), __consumer_offsets-36 -> (offset=0, leaderEpoch=0), __consumer_offsets-42 -> (offset=0, leaderEpoch=0), __consumer_offsets-18 -> (offset=0, leaderEpoch=0), __consumer_offsets-24 -> (offset=0, leaderEpoch=0), __consumer_offsets-38 -> (offset=0, leaderEpoch=0), __consumer_offsets-48 -> (offset=0, leaderEpoch=0), __consumer_offsets-2 -> (offset=0, leaderEpoch=0), __consumer_offsets-6 -> (offset=0, leaderEpoch=0), __consumer_offsets-14 -> (offset=0, leaderEpoch=0), __consumer_offsets-20 -> (offset=0, leaderEpoch=0), __consumer_offsets-0 -> (offset=0, leaderEpoch=0), __consumer_offsets-44 -> (offset=0, leaderEpoch=0), __consumer_offsets-12 -> (offset=0, leaderEpoch=0), __consumer_offsets-26 -> (offset=0, leaderEpoch=0), twitter-stream-1 -> (offset=0, leaderEpoch=0), __consumer_offsets-34 -> (offset=0, leaderEpoch=0), __consumer_offsets-10 -> (offset=0, leaderEpoch=0), __consumer_offsets-32 -> (offset=0, leaderEpoch=0), __consumer_offsets-40 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2024-08-26 19:00:33,784] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-28 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,789] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,791] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-6 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,792] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,792] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,792] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,792] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-32 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,792] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,792] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-36 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,792] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,793] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-14 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,793] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,793] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-44 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,793] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,793] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-18 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,793] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,793] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-48 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,793] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,797] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-40 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,798] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,798] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,798] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,798] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-30 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,798] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,798] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,798] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,799] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,799] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,799] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-26 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,799] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,799] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-34 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,799] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,801] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-8 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,801] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,801] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,801] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,801] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-38 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,801] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,803] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition twitter-stream-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,803] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,803] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-12 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,803] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,804] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-42 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,804] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,804] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-20 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,805] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,805] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-46 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,806] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,806] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-24 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,807] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,807] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-08-26 19:00:33,808] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2024-08-26 19:00:33,825] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,827] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,828] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,830] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,836] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,838] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,838] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,839] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,884] INFO Static member MemberMetadata(memberId=rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db, groupInstanceId=Some(null), clientId=rdkafka, clientHost=/172.19.0.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group twitter-group loaded with member id rdkafka-9da0232d-940d-4b69-af71-d8a3ebd605db at generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-08-26 19:00:33,889] INFO Static member MemberMetadata(memberId=rdkafka-5a1f7171-d18e-4310-9504-fdc7373bfec2, groupInstanceId=Some(null), clientId=rdkafka, clientHost=/172.19.0.5, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range), ).groupInstanceId of group twitter-group loaded with member id rdkafka-5a1f7171-d18e-4310-9504-fdc7373bfec2 at generation 2. (kafka.coordinator.group.GroupMetadata$)
[2024-08-26 19:00:33,900] INFO [GroupCoordinator 1]: Loading group metadata for twitter-group with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:00:33,914] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-25 in 87 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,915] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,916] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,917] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,918] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,919] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,921] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,921] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,921] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,923] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,923] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,926] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,926] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,926] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,926] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,926] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-2. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-8. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-14. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-20. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-26. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,927] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-32. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,928] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-38. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,928] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,928] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,928] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-44. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,929] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:33,930] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-08-26 19:00:34,689] INFO [GroupCoordinator 1]: Preparing to rebalance group twitter-group in state PreparingRebalance with old generation 2 (__consumer_offsets-25) (reason: Adding new member rdkafka-72da14d1-5099-4415-ad0a-86d8b6f9d7e6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:01:18,916] INFO [GroupCoordinator 1]: Member rdkafka-5a1f7171-d18e-4310-9504-fdc7373bfec2 in group twitter-group has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:01:18,923] INFO [GroupCoordinator 1]: Stabilized group twitter-group generation 3 (__consumer_offsets-25) (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:01:18,933] INFO [GroupCoordinator 1]: Assignment received from leader for group twitter-group for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2024-08-26 19:02:05,302] INFO Unable to read additional data from server sessionid 0x191900fa3e90001, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:02:05,637] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 19:02:05,643] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 19:02:05,643] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-08-26 19:02:11,407] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper: Try again
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 19:02:11,840] WARN Session 0x191900fa3e90001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 19:02:11,943] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:02:12,942] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 19:02:12,959] WARN Session 0x191900fa3e90001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 19:02:14,060] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[2024-08-26 19:02:14,256] WARN Session 0x191900fa3e90001 for server zookeeper:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.lang.IllegalArgumentException: Unable to canonicalize address zookeeper:2181 because it's not resolvable
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:71)
	at org.apache.zookeeper.SaslServerPrincipal.getServerPrincipal(SaslServerPrincipal.java:39)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:1087)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1139)
[2024-08-26 19:02:15,357] ERROR Unable to resolve address: zookeeper:2181 (org.apache.zookeeper.client.StaticHostProvider)
java.net.UnknownHostException: zookeeper
	at java.net.InetAddress.getAllByName0(InetAddress.java:1281)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at org.apache.zookeeper.client.StaticHostProvider$1.getAllByName(StaticHostProvider.java:92)
	at org.apache.zookeeper.client.StaticHostProvider.resolve(StaticHostProvider.java:147)
	at org.apache.zookeeper.client.StaticHostProvider.next(StaticHostProvider.java:375)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1137)
[Configuring] 'advertised.listeners' in '/opt/kafka/config/server.properties'
[Configuring] 'port' in '/opt/kafka/config/server.properties'
Excluding KAFKA_HOME from broker config
[Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[Configuring] 'listeners' in '/opt/kafka/config/server.properties'
Excluding KAFKA_VERSION from broker config
[Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[Configuring] 'offsets.topic.replication.factor' in '/opt/kafka/config/server.properties'
[Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[2024-08-26 19:06:27,260] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-08-26 19:06:27,854] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-08-26 19:06:27,924] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-08-26 19:06:27,931] INFO starting (kafka.server.KafkaServer)
[2024-08-26 19:06:27,932] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[2024-08-26 19:06:27,961] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:06:27,969] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:host.name=80119b3b5f3e (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.version=1.8.0_292 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.home=/usr/lib/jvm/zulu8-ca/jre (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.5.0.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.5.0.jar:/opt/kafka/bin/../libs/connect-file-2.5.0.jar:/opt/kafka/bin/../libs/connect-json-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-2.5.0.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.5.0.jar:/opt/kafka/bin/../libs/connect-runtime-2.5.0.jar:/opt/kafka/bin/../libs/connect-transforms-2.5.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-core-2.10.2.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.2.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.2.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.2.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.2.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.2.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javassist-3.26.0-GA.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-http-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-io-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-security-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-server-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jetty-util-9.4.24.v20191120.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.5.0.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.5.0.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.5.0.jar:/opt/kafka/bin/../libs/kafka-tools-2.5.0.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.5.0.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.7.1.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.3.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.1.jar:/opt/kafka/bin/../libs/reflections-0.9.12.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.3.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.30.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.30.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.library.path=/usr/lib/jvm/zulu8-ca/jre/lib/amd64/server:/usr/lib/jvm/zulu8-ca/jre/lib/amd64:/usr/lib/jvm/zulu8-ca/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,970] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:os.version=6.8.0-41-generic (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:os.memory.free=977MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,971] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,974] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7334aada (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:27,981] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-08-26 19:06:27,990] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:06:27,993] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:06:28,006] INFO Opening socket connection to server zookeeper/172.19.0.3:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:06:28,014] INFO Socket connection established, initiating session, client: /172.19.0.4:57506, server: zookeeper/172.19.0.3:2181 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:06:28,024] INFO Session establishment complete on server zookeeper/172.19.0.3:2181, sessionid = 0x191901515f70001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:06:28,030] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:06:28,390] INFO Cluster ID = m9Ch4gPJTLS-fyAW_ozvNg (kafka.server.KafkaServer)
[2024-08-26 19:06:28,517] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 19:06:28,537] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = PLAINTEXT://kafka-1:9092
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://0.0.0.0:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 2
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = zookeeper:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2024-08-26 19:06:28,576] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:28,577] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:28,578] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:28,627] INFO Loading logs. (kafka.log.LogManager)
[2024-08-26 19:06:28,716] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,721] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,774] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,775] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 106 ms (kafka.log.Log)
[2024-08-26 19:06:28,798] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,798] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,809] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,810] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2024-08-26 19:06:28,815] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,815] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,819] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,820] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 19:06:28,827] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,827] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,838] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,841] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2024-08-26 19:06:28,850] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,850] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,856] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,858] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:28,866] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,866] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,869] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,870] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 19:06:28,877] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,877] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,885] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,887] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 19:06:28,895] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,895] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,905] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,906] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:28,912] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,912] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,918] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,919] INFO [Log partition=twitter-stream-2, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 19:06:28,927] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,927] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,928] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,929] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:06:28,935] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,935] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,939] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,940] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:28,948] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,950] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,957] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,958] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:28,966] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,967] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,970] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,972] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:28,981] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,982] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,983] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,984] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:06:28,990] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:28,990] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,991] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:28,993] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:06:29,003] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,004] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,010] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,011] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:29,016] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,016] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,023] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,023] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 19:06:29,028] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,029] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,034] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,035] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:29,041] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,041] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,043] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,043] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,047] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,047] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,056] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,057] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 19:06:29,061] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,061] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,063] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,064] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,068] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,068] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,076] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,076] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:29,080] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,081] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,082] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,083] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,092] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,092] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,094] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,094] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,100] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,101] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,104] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,106] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:29,118] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,121] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,123] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,124] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:29,128] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,130] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,138] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,140] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:29,145] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,145] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,147] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,150] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:29,160] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,161] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,169] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,170] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:29,178] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,178] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,184] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,185] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 19:06:29,190] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,191] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,197] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,199] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:29,207] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,208] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,213] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,214] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2024-08-26 19:06:29,219] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,220] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,222] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,223] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 19:06:29,228] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,228] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,240] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,241] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2024-08-26 19:06:29,246] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,247] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,255] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,256] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2024-08-26 19:06:29,259] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,259] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,265] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,266] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2024-08-26 19:06:29,272] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,273] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,287] INFO [ProducerStateManager partition=__consumer_offsets-25] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2024-08-26 19:06:29,299] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,301] INFO [ProducerStateManager partition=__consumer_offsets-25] Loading producer state from snapshot file '/kafka/kafka-logs-1/__consumer_offsets-25/00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2024-08-26 19:06:29,312] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 43 ms (kafka.log.Log)
[2024-08-26 19:06:29,315] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,315] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,320] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,321] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2024-08-26 19:06:29,324] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,324] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,329] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,329] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2024-08-26 19:06:29,333] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,333] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,335] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,335] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,339] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,339] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,340] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,341] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:06:29,346] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,346] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,348] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,349] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2024-08-26 19:06:29,356] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,360] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,383] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,384] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2024-08-26 19:06:29,386] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,387] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,388] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,388] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:06:29,391] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,391] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,392] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,393] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:06:29,395] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,396] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,397] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,398] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,401] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,401] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,403] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,404] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2024-08-26 19:06:29,407] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,407] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,418] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,419] INFO [Log partition=twitter-stream-0, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2024-08-26 19:06:29,425] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,425] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,431] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,432] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:29,436] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,436] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,443] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,444] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2024-08-26 19:06:29,447] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,448] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,449] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,449] INFO [Log partition=twitter-stream-1, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2024-08-26 19:06:29,452] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,452] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,454] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,455] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,459] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Recovering unflushed segment 0 (kafka.log.Log)
[2024-08-26 19:06:29,459] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,460] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2024-08-26 19:06:29,461] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2024-08-26 19:06:29,464] INFO Logs loading complete in 837 ms. (kafka.log.LogManager)
[2024-08-26 19:06:29,481] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-08-26 19:06:29,483] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-08-26 19:06:29,961] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2024-08-26 19:06:30,011] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(0.0.0.0,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2024-08-26 19:06:30,019] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2024-08-26 19:06:30,049] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,051] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,051] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,052] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,076] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 19:06:30,168] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-08-26 19:06:30,195] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '113029862509838337' does not match current session '113029885898194945' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-08-26 19:06:30,207] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1819)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1757)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1724)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:95)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:273)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:44)
	at kafka.Kafka$.main(Kafka.scala:82)
	at kafka.Kafka.main(Kafka.scala)
[2024-08-26 19:06:30,212] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2024-08-26 19:06:30,213] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2024-08-26 19:06:30,218] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2024-08-26 19:06:30,222] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2024-08-26 19:06:30,223] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 19:06:30,224] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 19:06:30,225] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-08-26 19:06:30,225] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2024-08-26 19:06:30,227] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-08-26 19:06:30,228] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 19:06:30,228] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-08-26 19:06:30,228] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,251] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,251] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,252] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,450] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,450] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,451] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,452] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,452] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,453] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,653] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,653] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-08-26 19:06:30,663] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2024-08-26 19:06:30,664] INFO Shutting down. (kafka.log.LogManager)
[2024-08-26 19:06:30,794] INFO Shutdown complete. (kafka.log.LogManager)
[2024-08-26 19:06:30,795] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:06:30,904] INFO Session: 0x191901515f70001 closed (org.apache.zookeeper.ZooKeeper)
[2024-08-26 19:06:30,905] INFO EventThread shut down for session: 0x191901515f70001 (org.apache.zookeeper.ClientCnxn)
[2024-08-26 19:06:30,905] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-08-26 19:06:30,906] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,577] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,577] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,577] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,579] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,579] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:31,580] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:32,580] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:32,580] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-08-26 19:06:32,581] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2024-08-26 19:06:32,631] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2024-08-26 19:06:32,640] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2024-08-26 19:06:32,640] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2024-08-26 19:06:32,642] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
